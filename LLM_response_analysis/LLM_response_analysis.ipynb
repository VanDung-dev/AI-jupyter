{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Phân tích cách AI/LLM trả lời\n",
    "\n",
    "Mục tiêu: pipeline từ load log -> preprocess -> metrics -> clustering -> visualization\n",
    "Hướng dẫn: đặt file log dạng CSV với cột: id, prompt, response, timestamp, user_id (tùy chọn)\n"
   ],
   "id": "889fa4a83ddde507"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## PHẦN 0: Cài đặt (chạy 1 lần)\n",
    "\n",
    "Phần này cung cấp các lệnh cài đặt cho các gói cần thiết. Bao gồm các thư viện xử lý dữ liệu (pandas, numpy), công cụ trực quan hóa (matplotlib, plotly), thư viện học máy (scikit-learn, sentence-transformers) và các thư viện khác."
   ],
   "id": "26662a9a202b33c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install pandas numpy matplotlib scikit-learn sentence-transformers plotly tqdm jinja2",
   "id": "e6663b8cb09b53f7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## PHẦN 1: Imports\n",
    "Import tất cả các thư viện cần thiết cho việc thao tác dữ liệu, học máy và trực quan hóa. Đồng thời thử import thư viện sentence-transformers cung cấp khả năng embedding văn bản nâng cao, với phương án dự phòng là TF-IDF nếu không có sẵn."
   ],
   "id": "e2c7a8762e974967"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# PHẦN 1: Imports\n",
    "import os\n",
    "import re\n",
    "from typing import List, Dict, Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "# Optional: sentence-transformers for good embeddings. Nếu không có, sẽ fallback sang TF-IDF\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    USE_SENTENCE_TRANSFORMER = True\n",
    "except Exception:\n",
    "    USE_SENTENCE_TRANSFORMER = False"
   ],
   "id": "ff3306db79423212"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## PHẦN 2: Các hàm tiện ích\n",
    "\n",
    "Hàm `load_logs` tải nhật ký cuộc trò chuyện từ file CSV hoặc JSON và chuẩn hóa tên cột. Nó ánh xạ các tên cột có thể có sang tên chuẩn (prompt, response, timestamp, id).\n",
    "Hàm `normalize_text` làm sạch văn bản bằng cách loại bỏ khoảng trắng thừa và chuẩn hóa khoảng cách."
   ],
   "id": "c37c5de212468d5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def load_logs(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load CSV/JSON logs. Trả về DataFrame chuẩn hóa cột: id, prompt, response, timestamp\"\"\"\n",
    "    if path.endswith('.csv'):\n",
    "        df = pd.read_csv(path)\n",
    "    elif path.endswith('.json') or path.endswith('.jsonl'):\n",
    "        df = pd.read_json(path, lines=path.endswith('.jsonl'))\n",
    "    else:\n",
    "        raise ValueError('Chỉ hỗ trợ CSV hoặc JSON(.jsonl)')\n",
    "\n",
    "    # chuẩn hóa tên cột phổ biến\n",
    "    mapping = {}\n",
    "    for c in df.columns:\n",
    "        low = c.lower()\n",
    "        if 'prompt' in low or 'question' in low or 'input' in low:\n",
    "            mapping[c] = 'prompt'\n",
    "        if 'response' in low or 'answer' in low or 'reply' in low:\n",
    "            mapping[c] = 'response'\n",
    "        if 'time' in low or 'timestamp' in low:\n",
    "            mapping[c] = 'timestamp'\n",
    "        if 'id' == low or low.endswith('_id'):\n",
    "            mapping[c] = 'id'\n",
    "\n",
    "    df = df.rename(columns=mapping)\n",
    "    if 'prompt' not in df.columns or 'response' not in df.columns:\n",
    "        raise ValueError('File log phải có cột prompt và response (hoặc tên tương tự)')\n",
    "\n",
    "    if 'timestamp' in df.columns:\n",
    "        try:\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        except Exception:\n",
    "            pass\n",
    "    else:\n",
    "        df['timestamp'] = pd.Timestamp.now()\n",
    "\n",
    "    if 'id' not in df.columns:\n",
    "        df['id'] = range(len(df))\n",
    "\n",
    "    return df"
   ],
   "id": "53dfeca44450194e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def normalize_text(s: str) -> str:\n",
    "    s = s or ''\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    return s"
   ],
   "id": "9689175afbb35f0f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## PHẦN 3: Embeddings/Vectorization\n",
    "\n",
    "Lớp `Embedder` xử lý việc vector hóa văn bản sử dụng Sentence Transformers (nâng cao) hoặc TF-IDF (phương án dự phòng). Nó chuyển đổi văn bản thành các vector số có thể xử lý toán học."
   ],
   "id": "c8f65a5260975a3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Embedder:\n",
    "    def __init__(self, model_name: str = 'all-MiniLM-L6-v2'):\n",
    "        self.use_st = USE_SENTENCE_TRANSFORMER\n",
    "        if self.use_st:\n",
    "            try:\n",
    "                print('Loading SentenceTransformer:', model_name)\n",
    "                self.model = SentenceTransformer(model_name)\n",
    "            except Exception as e:\n",
    "                print('Không load được sentence-transformer, fallback TF-IDF.', e)\n",
    "                self.use_st = False\n",
    "                self.model = None\n",
    "        if not self.use_st:\n",
    "            self.vectorizer = TfidfVectorizer(max_features=20000, ngram_range=(1,2))\n",
    "            self.model = None\n",
    "\n",
    "    def fit_transform(self, texts: List[str]) -> np.ndarray:\n",
    "        texts = [normalize_text(t) for t in texts]\n",
    "        if self.use_st and self.model is not None:\n",
    "            embs = np.array(self.model.encode(texts, show_progress_bar=True))\n",
    "            return embs\n",
    "        else:\n",
    "            X = self.vectorizer.fit_transform(texts)\n",
    "            return X.toarray()\n",
    "\n",
    "    def transform(self, texts: List[str]) -> np.ndarray:\n",
    "        texts = [normalize_text(t) for t in texts]\n",
    "        if self.use_st and self.model is not None:\n",
    "            return np.array(self.model.encode(texts, show_progress_bar=False))\n",
    "        else:\n",
    "            X = self.vectorizer.transform(texts)\n",
    "            return X.toarray()"
   ],
   "id": "351376fa319a176b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## PHẦN 4: Metrics - similarity, hallucination proxies, structure parsing\n",
    "\n",
    "Phần này định nghĩa một số chỉ số chính:\n",
    "* Các hàm tính độ tương đồng để đo lường mức độ liên quan giữa prompt và response\n",
    "* Ước lượng độ tự tin dựa trên các dấu hiệu ngôn ngữ\n",
    "* Phát hiện các tuyên bố có thể xác minh được (factual claims)\n",
    "* Tính điểm hallucination kết hợp nhiều yếu tố có thể chỉ ra khi LLM tạo ra thông tin sai lệch"
   ],
   "id": "c1935ab8cdec9c91"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def pairwise_similarity_matrix(a: np.ndarray, b: np.ndarray) -> np.ndarray:\n",
    "    return cosine_similarity(a, b)"
   ],
   "id": "d8b56fb54e74593c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def response_prompt_similarity(emb_prompts: np.ndarray, emb_responses: np.ndarray) -> np.ndarray:\n",
    "    # cosine similarity giữa prompt và response từng cặp (diagonal)\n",
    "    sims = np.array([cosine_similarity([ep], [er])[0,0] for ep, er in zip(emb_prompts, emb_responses)])\n",
    "    return sims"
   ],
   "id": "5a9b7417f13aa106"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def estimate_confidence_proxy(text: str) -> float:\n",
    "    \"\"\"Một proxy đơn giản cho 'độ tự tin' dựa trên ngôn ngữ:\n",
    "    - câu khẳng định (contains 'definitely', 'certainly', 'always', 'will') tăng điểm\n",
    "    - từ mơ hồ ('maybe','could','might','possibly') giảm điểm\n",
    "    Trả về 0..1\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    strong = len(re.findall(r\"\\b(definitely|certainly|always|will|must|absolutely|surely)\\b\", text))\n",
    "    weak = len(re.findall(r\"\\b(maybe|could|might|possibly|seems|appear)\\b\", text))\n",
    "    tokens = max(1, len(text.split()))\n",
    "    score = (strong - 0.5*weak) / (np.log(tokens+1) + 1)\n",
    "    # Kẹp đến 0..1 thông qua sigmoid-like\n",
    "    score = 1/(1+np.exp(-score))\n",
    "    return float(score)"
   ],
   "id": "e7d1d40e3cbc77d5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def detect_factual_claims(text: str, max_claim_tokens: int = 20) -> List[str]:\n",
    "    # heuristic: câu chứa số, ngày, tên riêng + động từ khẳng định\n",
    "    claims = []\n",
    "    sentences = re.split(r'[\\.\\n]+', text)\n",
    "    for s in sentences:\n",
    "        if len(s.split()) < 3:\n",
    "            continue\n",
    "        if re.search(r'\\b\\d{2,4}\\b', s) or re.search(r'\\b(in|on|at) \\b', s):\n",
    "            claims.append(s.strip())\n",
    "        # detect existence of proper nouns (capitalized words) - naive\n",
    "        if re.search(r'\\b[A-Z][a-z]{2,}\\b', s) and len(s.split()) <= max_claim_tokens:\n",
    "            claims.append(s.strip())\n",
    "    return list(dict.fromkeys(claims))"
   ],
   "id": "9e92ada4f3c9b40e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def estimate_hallucination_score(response: str, prompt: str = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Tính toán điểm hallucination dựa trên nhiều yếu tố:\n",
    "    1. Độ tự tin ngôn ngữ (như trước)\n",
    "    2. Sự không nhất quán nội tại\n",
    "    3.Mức độ chi tiết không chắc chắn\n",
    "    4. Phân tích cấu trúc phủ định\n",
    "    \"\"\"\n",
    "    response= response.lower()\n",
    "\n",
    "    # 1. Confidence scoring (như trước nhưng cải tiến)\n",
    "    strong_assertions = len(re.findall(r\"\\b(definitely|certainly|always|will|must|absolutely|surely|undoubtedly|clearly)\\b\", response))\n",
    "    uncertain_terms = len(re.findall(r\"\\b(maybe|could|might|possibly|seems|appear|likely|probably|perhaps|potentially)\\b\", response))\n",
    "    disclaimer_phrases = len(re.findall(r\"\\b(as far as i know|to my knowledge|i believe|i think|in my opinion|supposedly|reportedly|allegedly)\\b\", response))\n",
    "\n",
    "    confidence_score = (strong_assertions - 0.5 * uncertain_terms - 0.7 * disclaimer_phrases) / max(1, len(response.split()))\n",
    "    confidence_score = 1 / (1 + np.exp(-confidence_score))  #Normalize to 0-1\n",
    "\n",
    "    # 2. Self-contradiction detection\n",
    "    contradiction_indicators = len(re.findall(r\"\\b(but|however|although|though|yet|nevertheless|nonetheless|on the other hand)\\b\", response))\n",
    "    contradiction_score = min(1.0, contradiction_indicators / max(1, len(response.split()) / 20))\n",
    "\n",
    "    # 3. Over-specificity detection (potentially made-up details)\n",
    "    digits_count = len(re.findall(r'\\d+', response))\n",
    "    specific_detail_patterns = len(re.findall(r\"(in \\d{4}|since\\d{4}|for \\d+ years|costs? \\$?\\d+|population (of )?\\d+|length \\d+)\", response))\n",
    "    over_specificity_score = min(1.0, (digits_count + specific_detail_patterns) / max(1, len(response.split()) / 10))\n",
    "\n",
    "    # 4. Negation structure analysis\n",
    "    negations = len(re.findall(r\"\\b(not|no|never|neither|nowhere|nothing|nobody|none)\\b\", response))\n",
    "    negation_score = min(1.0, negations / max(1,len(response.split()) / 15))\n",
    "\n",
    "    # Tổng hợp điểm hallucination (cao hơn = khả năng hallucination cao hơn)\n",
    "    hallucination_score = (\n",
    "        0.3 * confidence_score +           # Tự tin quá mức có thể là dấu hiệu của hallucination\n",
    "        0.25 * contradiction_score +       # Tự mâu thuẫn\n",
    "        0.25 * over_specificity_score +    # Chi tiết cụ thể nghi ngờ\n",
    "        0.2 * negation_score               # Phủ nhận phức tạp có thể che giấu sự không chắc chắn\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'hallucination_score': float(hallucination_score),\n",
    "        'confidence_component': float(confidence_score),\n",
    "        'contradiction_component': float(contradiction_score),\n",
    "        'specificity_component': float(over_specificity_score),\n",
    "        'negation_component': float(negation_score)\n",
    "    }"
   ],
   "id": "306910655a761f6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## PHẦN 5: Structural parsing - tách thành mở bài, giải thích, ví dụ, kết luận\n",
    "\n",
    "Hàm này cố gắng phân tích cấu trúc của các phản hồi, chia chúng thành các phần: giới thiệu, giải thích, ví dụ và kết luận dựa trên việc phát hiện từ khóa."
   ],
   "id": "821ca1c31035bb4a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def split_structure(text: str) -> Dict[str, str]:\n",
    "    # heuristic: dùng các dấu hiệu từ khoá\n",
    "    parts = {'intro': '', 'explain': '', 'example': '', 'conclusion': ''}\n",
    "    text = text.strip()\n",
    "    # tìm example keywords\n",
    "    ex_pos = re.search(r\"\\b(example|ví dụ|for example|e\\.g\\.|e.g\\.)\\b\", text, flags=re.I)\n",
    "    concl_pos = re.search(r\"\\b(in summary|tóm lại|kết luận|to conclude|therefore)\\b\", text, flags=re.I)\n",
    "\n",
    "    if ex_pos:\n",
    "        parts['example'] = text[ex_pos.start():]\n",
    "        text = text[:ex_pos.start()]\n",
    "    if concl_pos:\n",
    "        parts['conclusion'] = text[concl_pos.start():]\n",
    "        text = text[:concl_pos.start()]\n",
    "\n",
    "    # split remaining into intro (first sentence/2) and explain(rest)\n",
    "    sents = re.split(r'(?<=[\\.!?])\\s+', text)\n",
    "    if len(sents) <= 2:\n",
    "        parts['intro'] = ' '.join(sents)\n",
    "    else:\n",
    "        parts['intro'] = sents[0]\n",
    "        parts['explain'] = ' '.join(sents[1:])\n",
    "\n",
    "    # clean\n",
    "    for k in parts:\n",
    "        parts[k] = parts[k].strip()\n",
    "    return parts"
   ],
   "id": "d6094819a6ff0ad8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## PHẦN 6: Analysis pipeline\n",
    "Đây là pipeline phân tích chính điều phối tất cả các thành phần:\n",
    "* Chuẩn hóa văn bản\n",
    "* Vector hóa văn bản\n",
    "* Tính toán độ tương đồng\n",
    "* Phân tích hallucination\n",
    "* Phát hiện tuyên bố có thể xác minh\n",
    "* Phân tích cấu trúc\n",
    "* Phân cụm các phản hồi để xác định mẫu\n",
    "* Giảm chiều để trực quan hóa"
   ],
   "id": "ab8f7374c0ee2173"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def run_analysis(df: pd.DataFrame, top_k_clusters: int = 6) -> Dict[str, Any]:\n",
    "    df = df.copy()\n",
    "    df['prompt'] = df['prompt'].astype(str).apply(normalize_text)\n",
    "    df['response'] = df['response'].astype(str).apply(normalize_text)\n",
    "\n",
    "    emb = Embedder()\n",
    "    print('Fitting prompt embeddings...')\n",
    "    emb_prompts = emb.fit_transform(df['prompt'].tolist())\n",
    "    print('Fitting response embeddings...')\n",
    "    emb_responses = emb.transform(df['response'].tolist())\n",
    "\n",
    "    # Sự giống nhau trên mỗi cặp\n",
    "    sims = response_prompt_similarity(emb_prompts, emb_responses)\n",
    "    df['prompt_response_sim'] = sims\n",
    "\n",
    "    # Phân tích ảo giác (Hallucination)\n",
    "    hallucination_results = df.apply(lambda row: estimate_hallucination_score(row['response'], row['prompt']), axis=1)\n",
    "    df['hallucination_score'] = [r['hallucination_score'] for r in hallucination_results]\n",
    "    df['confidence_component'] =[r['confidence_component'] for r in hallucination_results]\n",
    "    df['contradiction_component'] = [r['contradiction_component'] for r in hallucination_results]\n",
    "    df['specificity_component'] = [r['specificity_component'] for r in hallucination_results]\n",
    "    df['negation_component'] = [r['negation_component'] for r in hallucination_results]\n",
    "\n",
    "    # Tuyên bố thực tế (giữ nguyên bản gốc để tương thích ngược)\n",
    "    df['claims'] = df['response'].apply(detect_factual_claims)\n",
    "    df['num_claims'] = df['claims'].apply(len)\n",
    "\n",
    "    # cấu trúc\n",
    "    struct = df['response'].apply(split_structure)\n",
    "    df['intro'] = struct.apply(lambda x: x['intro'])\n",
    "    df['explain'] = struct.apply(lambda x: x['explain'])\n",
    "    df['example'] = struct.apply(lambda x: x['example'])\n",
    "    df['conclusion'] = struct.apply(lambda x: x['conclusion'])\n",
    "\n",
    "    # Phân cụm phản hồi để tìm kiểu\n",
    "    print('Clustering responses...')\n",
    "    # bình thường hoá\n",
    "    X = emb_responses\n",
    "    Xn = normalize(X)\n",
    "    k = min(top_k_clusters, max(2, len(df)//10))\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    labels = kmeans.fit_predict(Xn)\n",
    "    df['cluster'] = labels\n",
    "\n",
    "    # PCA để trực quan hóa\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    pcs = pca.fit_transform(Xn)\n",
    "    df['pc1'] = pcs[:,0]\n",
    "    df['pc2'] = pcs[:,1]\n",
    "\n",
    "    results = {\n",
    "        'df': df,\n",
    "        'emb_prompts': emb_prompts,\n",
    "        'emb_responses': emb_responses,\n",
    "        'kmeans': kmeans,\n",
    "        'pca': pca,\n",
    "    }\n",
    "    return results"
   ],
   "id": "56f80218b5b7ac58"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## PHẦN 7: Visualization helpers\n",
    "Các hàm này cung cấp khả năng trực quan hóa:\n",
    "* Biểu đồ histogram của độ tương đồng prompt-response\n",
    "* Biểu đồ phân tán tương tác của các phản hồi được phân cụm\n",
    "* Trích xuất các từ khóa hàng đầu cho mỗi cụm"
   ],
   "id": "a1304c3dd34329bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_similarity_hist(df: pd.DataFrame):\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.hist(df['prompt_response_sim'].dropna(), bins=30)\n",
    "    plt.title('Prompt-Response similarity distribution')\n",
    "    plt.xlabel('cosine similarity')\n",
    "    plt.ylabel('count')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "abd307f038ff9150"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_clusters_interactive(df: pd.DataFrame):\n",
    "    fig = px.scatter(df, x='pc1', y='pc2', color=df['cluster'].astype(str),\n",
    "                     hover_data=['id','prompt','response','prompt_response_sim','confidence_component','num_claims'])\n",
    "    fig.update_layout(title='Response clusters (interactive)')\n",
    "    fig.show()"
   ],
   "id": "4fe81163836d899c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def top_terms_per_cluster(df: pd.DataFrame, n_terms: int = 8):\n",
    "    # ước tính các thuật ngữ TF-IDF hàng đầu trên mỗi cụm (phỏng đoán nhanh)\n",
    "    vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1,2))\n",
    "    X = vectorizer.fit_transform(df['response'].tolist())\n",
    "    terms = np.array(vectorizer.get_feature_names_out())\n",
    "    clusters = df['cluster'].unique()\n",
    "    out = {}\n",
    "    for c in clusters:\n",
    "        idx = df['cluster'] == c\n",
    "        avg = X[idx.values].mean(axis=0).A1\n",
    "        topi = np.argsort(avg)[-n_terms:][::-1]\n",
    "        out[c] = terms[topi].tolist()\n",
    "    return out"
   ],
   "id": "cd71c54b6fe81cec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## PHẦN 8: Example usage\n",
    "\n",
    "Phần này trình bày cách sử dụng pipeline phân tích với tập dữ liệu mẫu hoặc file log thực tế. Nó cho thấy cách chạy phân tích, hiển thị kết quả, trực quan hóa dữ liệu và xuất kết quả."
   ],
   "id": "a0b74d7615cc4ad1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ví dụ giả sử có file logs.csv\n",
    "example_path = 'logs.csv'\n",
    "if not os.path.exists(example_path):\n",
    "    print('Không tìm thấy logs.csv. Tạo sample nhỏ để demo...')\n",
    "    sample = [\n",
    "        {'id':0, 'prompt':'Làm thế nào để sắp xếp một list trong Python?', 'response':'Bạn có thể dùng sorted(list) hoặc list.sort(). Ví dụ: sorted([3,1,2]).'},\n",
    "        {'id':1, 'prompt':'Giải thích time complexity của quicksort', 'response':'Quicksort trung bình O(n log n), worst-case O(n^2). Sử dụng pivot tốt để tránh worst-case.'},\n",
    "        {'id':2, 'prompt':'Viết ví dụ SQL join', 'response':'Ví dụ: SELECT * FROM A JOIN B ON A.id = B.a_id;'},\n",
    "    ]\n",
    "    df = pd.DataFrame(sample)\n",
    "else:\n",
    "    df = load_logs(example_path)\n",
    "\n",
    "res = run_analysis(df, top_k_clusters=4)\n",
    "df_out = res['df']\n",
    "\n",
    "print('\\n--- Summary ---')\n",
    "print('Số bản ghi:', len(df_out))\n",
    "print('Sim mean:', df_out['prompt_response_sim'].mean())\n",
    "print('Hallucination score mean:', df_out['hallucination_score'].mean())\n",
    "print('Confidence component mean:', df_out['confidence_component'].mean())\n",
    "\n",
    "# Hiển thị phân tích ảo giác cho các mục hàng đầu\n",
    "print('\\n--- Top potential hallucinations ---')\n",
    "top_hallucinations = df_out.nlargest(3, 'hallucination_score')[['prompt', 'response', 'hallucination_score']]\n",
    "for _, row in top_hallucinations.iterrows():\n",
    "    print(f\"Hallucination Score: {row['hallucination_score']:.3f}\")\n",
    "    print(f\"Prompt: {row['prompt']}\")\n",
    "    print(f\"Response: {row['response'][:100]}...\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "plot_similarity_hist(df_out)\n",
    "plot_clusters_interactive(df_out)\n",
    "\n",
    "print('\\nTop terms per cluster:')\n",
    "print(top_terms_per_cluster(df_out))\n",
    "\n",
    "# Xuất kết quả\n",
    "df_out.to_csv('analysis_results.csv', index=False)\n",
    "print('Kết quả đã lưu: analysis_results.csv')"
   ],
   "id": "5e3c759e63e27a53"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
